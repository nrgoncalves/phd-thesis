\def\baselinestretch{1}
\chapter{Conclusions}
\ifpdf
    \graphicspath{{discussion/discussion-figs/PNG/}{discussion/discussion-figs/PDF/}{discussion/discussion-figs/}}
\else
    \graphicspath{{discussion/discussion-figs/EPS/}{discussion/discussion-figs/}}
\fi

\def\baselinestretch{1.66}

In this thesis, I present theoretical and experimental studies that aim to advance our knowledge about the neural computations that support stereopsis. In what follows, I shall discuss the implications --- and limitations --- of our findings for our understanding of stereopsis.


\subsection{Key contributions}


\subsubsection*{``What not'' detectors}

Strictly, the definition of binocular disparity --- the difference between the positions of corresponding features in the left and right eyes --- requires correspondence between the elements of the left and right images. Horace Barlow and colleagues \cite{Barlow:1967bs} incorporated this idea in the interpretation of their findings that individual neurons in cat V1 have similar receptive fields in slightly different positions in the left and right eye: the similarity between the left and right receptive fields implied that they could be detecting the presence of similar features, while the difference in the RF position in the left and right eyes could encode binocular disparity. Later, this intuitive interpretation was found to be over-simplistic because many neurons have highly dissimilar receptive fields in the left and right eyes --- instead of being disparate in their position, they are also very different, often antagonistic, in their phase \cite{DeAngelis:1991mb}. This has long been regarded as a puzzle in the field.

Prior to this work, it was suggested that neurons with dissimilar binocular receptive fields could help in improving the accuracy of disparity estimation based on more conventional neurons (i.e. neurons with identical receptive field structure across the eyes) \cite{Read:2007nx}. Here, I show that neurons with antagonistic receptive field structure --- which we term ``what not'' detectors --- develop by optimizing neural networks for estimating disparity, and that they do not rely on the responses of neurons with similar receptive fields across the eyes (indeed, for frontoparallel surfaces, ``what not'' detectors can perfectly recover depth from binocular images). This suggests that neurons that were once seen as forming the basis for a neural mechanism for stereopsis \cite{Barlow:1967bs} may not be as important as we currently assume them to be.

As a consequence, our understanding of how the brain extracts depth from binocular disparity, which usually relies on the idea of finding correspondence between features across the eyes, may need reconsideration. It is hard to see how neurons with entirely dissimilar binocular receptive fields could look for similar elements across the eyes. In other words, how can such neurons explicitly solve the correspondence problem? The responses of these neurons, which turn out to be the most informative to infer depth, do not seem to relate in any way to matching of similar features across the eyes. In this sense, I argue that they should not be thought of as neurons that attempt to explicitly solve the correspondence problem.

Given that the definition of binocular disparity requires binocular correspondence, an apparent contradiction emerges at this point: how can a neuron not be related to solving the correspondence problem, but yet be very informative about the depth contained in disparate binocular images? I argue that if we accept that ``what not'' neurons do not play a role in determining stereo-correspondence, we should be prepared to accept that these neurons do not encode binocular disparity according to its strict definition --- the positional difference between corresponding features in the left and right eyes. Because these neurons are the most informative for estimating depth, we should also be prepared to accept that binocular disparity --- the \textit{positional} difference between \textit{corresponding} elements --- might not be that important for depth perception. From this standpoint, these neurons seem to exploit \textit{differences} (not only positional) between the left and right images as their cue to depth. This formulation may be helpful in reconciling stereopsis with and without binocular correspondence.


\subsubsection*{Optimal representations for computation}

One approach to investigate neural computations is to start with a formal examination of the computational goals for a particular task. This approach was first formulated by David Marr \cite{Marr:1976dq,Marr:1982:VCI:1095712}, and was at the heart of early theoretical work on stereopsis \cite{Sperling:1970ys,Marr:1976dq}. In the case of stereopsis, Marr divided the computational problem in two main parts: (i) establishing correspondence between the left and right images for each image element, and (ii) computing the binocular disparity between corresponding points. David Marr's formulation of the stereo computational problem was thus very intuitive. Having defined the computational problem (and some constraints), an algorithm design phase would then follow.

This approach is elegant and praised by many researchers to this date \cite{Carandini:2012ce,POGGIO1981258}. However, it is not without its considerable pitfalls \cite{Anderson:2015fu,doi:10.1068/p7275}. For instance, an incorrect or incomplete specification of the computational problem will likely affect the subsequent level of analysis. A similar argument extends to the algorithmic level as well. As Minsky highlighted, one problem with the `Marrian' approach is that it requires heavy feature hand-engineering, and very often the features that we engineer provide highly suboptimal representations \cite{Stork:1996:HLC:548366}.

This thesis also stems from thinking about computation in the first place, but relying on neural networks to learn features allows one to build better representations. In turn, this approach does require the loose definition of the building blocks of the algorithm that performs the computation. Here, previous knowledge of the basic computational properties of disparity selective cells in V1 was instrumental in defining the building blocks of the neural network. In other cases (e.g. object recognition), defining such building blocks might be considerably more ambiguous because less is known about the properties and hierarchy of neurons involved in the computation of interest. Note, however, that the \textit{a priori} definition of these building blocks does not uniquely define the computation that is performed by neural networks. I argue that this approach --- based on optimizing neural networks for particular neural computations --- forms the basis for a new `Marrian' approach for the machine learning era.


\subsubsection*{Perception and binocular anticorrelation}

Can humans extract disparity information from anticorrelated features? This has been one of the most prominent questions in stereopsis research over the past 30 years \cite{JULESZ:1964ff,Cogan:1993yr,Cumming:1998ib,Read:2000kx}. Using anticorrelated RDS in a variety of configurations, Hibbard and colleagues tested a large sample of observers and found no evidence to suggest that humans are able to extract depth information from anticorrelated binocular disparities \cite{Hibbard2014}. A key contribution of this thesis is the demonstration that humans are indeed sensitive to binocular disparities imposed in anticorrelated features. I found that introducing small variations in anticorrelated disparities (of approximately 6 arcmin) can have a drastic impact in the observer's perceptual experience. My experiments suggest that the mechanism by which anticorrelation is sensed is well tuned (as opposed to categorical or non-specific) and likely to be supported by primary visual cortex. On the basis of temporal onset asynchrony between correlated and anticorrelated features, I propose that the mechanism by which anticorrelated disparities affect perception is mediated by fast, forward suppression at the level of V1 complex cells.

\subsubsection*{Cortical specialization and perceptual correlates of stereopsis}

We have known for more than a decade that dorsomedial visual cortex holds neural representations that are somewhat related to stereoscopic perception \cite{Backus:2001ly,Tsao:2003lk}. Here I extend this knowledge by showing that these visual areas --- namely V3A and V3B/KO --- hold such representations in systematic cortical maps, which are organized not only by disparity preference but also by other tuning properties (e.g. categorical vs tuned). I also show that, in these areas, the specificity of responses to individual disparities decreases with disparity magnitude and that the rate at which this happens matches psychophysical data. In sum, the evidence gathered here strengthens the hypothesis that dorsomedial visual cortex may play a critical role in processing stereoscopic information, and contributes to closing the gap between neural circuits and stereoscopic perception.


\subsection{Limitations}


\subsubsection*{Model optimization under real-world, naturalistic conditions}

In Chapter 2, I trained a neural network to extract disparity from naturalistic binocular images, and found that the neural network explained interesting neurophysiological and perceptual observations. While this is a significant step compared to previous approaches \cite{Lippert:2000fk,Lippert:2001fk}, the network architecture is oversimplified compared to the visual system. In particular, we know that stereopsis recruits multiple visual areas at different stages of the cortical hierarchy, but such areas were not considered during modelling. We also know that the oculomotor system is tightly interconnected with stereoscopic processing \cite{Masson:1997jq,Masson:2002qi}. While the findings reported in Chapter 2 can be very informative about stereoscopic processing in V1, they do not address the wider stereoscopic system as a whole.  

\subsubsection*{Gap between models of disparity selectivity and perception}

I start this thesis by demonstrating how retinal images could be encoded and represented in primary visual cortex (Chapter 2). Later, I show that areas V3A and V3B/KO hold highly-specialized representations that are likely to support stereoscopic perception. But what happens in between? The experiments I conducted do not provide an answer to this question. I did find evidence that cortical organization builds up as we move along the dorsal stream, but I was not able to characterize the computations performed by mid-level areas. There is evidence that the dorsal stream may be involved in performing figure-ground segregation in slanted random-dot stereograms \cite{Ban:2015cr}, but we still lack an understanding of the computations that generalizes to arbitrary stereoscopic stimuli. Thus, more experimental and theoretical work needs to be carried out in order to fully understand and test the hierarchy of computations that supports stereoscopic perception. 

\subsubsection*{Nature of cortical specialization for stereopsis}

Although nearly every experimental technique has been used to investigate stereopsis, the field has not been able to converge on a single specialized area for stereopsis. Instead, the evidence so far points to distributed coding across many cortical areas, mainly in the ventral and dorsal visual streams. Here I report evidence of systematic cortical organization for depth from binocular disparity in areas V3A and V3B/KO. However, it is possible that similar organization is present elsewhere in visual cortex --- perhaps in the ventral stream, which I was unable to image due to field-of-view limitations. Furthermore, we have yet to characterize this cortical organization: I show that the disparity preferences are persistently represented in the cortex, but I was not able to identify the rules that govern the spatial arrangement of disparity preferences. It would be interesting to compare the results obtained in the dorsal stream with preference maps for the ventral stream, which would hopefully help to further dissociate the role of the ventral and dorsal streams in stereoscopic processing.

Another question that remains to be answered is concerned with the purpose of such cortical organization. Previous work suggests that cortical organization might be intimately related to neural activity that correlates with perception on a trial-by-trial basis \cite{Nienborg:2014fu}. I was unable to test this with fMRI due to its limited temporal resolution. Based on the literature, it seems that a correlation exists between the presence of cortical organization and neural signals related to depth perception \cite{Clery:2015lh,Nienborg:2014fu,Nienborg:2007ly,Nienborg:2006qo,Shiozaki:2012ys,Uka:2004mg,DeAngelis:1998df}.


\subsection{Future work}

\subsubsection*{Towards more powerful and integrated models of stereopsis}

Here I explored simple models of stereopsis that were mostly concerned with the computation of local, zero-order disparity. Future work might benefit from extending models to account for more complex stereoscopic judgments, such as those involving shape recognition \cite{Verhoef:2015cz,Verhoef:2012dg,Verhoef:2010gb,Orban:2006kn,Janssen:1999nx}. This would also promote an approximation between computational models of stereopsis and form vision --- an area that is yet to be explored. Additionally, considering the dynamics of the interplay between the visual and the oculomotor system will be an important step towards achieving a satisfying account of stereoscopic perception as a whole. Here, deep neural networks may prove useful because they excel at complex visual tasks and they can implement recurrent processing within and between networks \cite{LeCun:2015ez}.

\subsubsection*{What is the role of suppression?}

The theoretical and psychophysical work gathered here suggests that suppression may play an important role in stereopsis. Neurophysiologists have only recently started characterizing suppression in disparity selective cells in V1 \cite{Tanabe:2011pt,Tanabe:2014ud}, but the data so far seem to support this conclusion \cite{Tanabe:2011pt}. Further work will be necessary to better understand the suppressive mechanisms involved, but the existent data and the results that I report here invite some speculation. Tanabe and Cumming found that suppression is only slightly delayed with respect to excitation, which would point to a fast, feedforward suppression mechanism --- perhaps akin to that of cross-orientation suppression in V1 \cite{Smith:2006uq}. This is in agreement with the predictions stemming from this theoretical work. The existence of a fast suppressive mechanism is also consistent with my psychophysical data, where I found a detrimental effect of introducing a very short onset asynchrony between signals that are thought to drive excitation and suppression of specific disparity detectors. However, these psychophysical results also indicate the existence of a suppressive effect that is spatially more broad than the smallest excitatory effects. This could point to a different suppressive mechanism, perhaps mediated by slower and less precise feedback connections. Understanding the precise suppressive mechanisms requires further neurophysiological research, but on the basis of the data presented above I speculate that two suppressive mechanisms at the level of V1 --- a fast mechanism based on feedforward connections, and a slower one based on lateral or feedback connections.


\subsubsection*{Whole-brain imaging at submillimeter resolution}

Based on the dense connectivity between different visual areas involved in stereopsis \ref{fig:viscortex}, it is likely that stereoscopic perception relies on a tight interplay between these areas. This considerably complicates the study of stereoscopic perception because neurophysiologists are typically constrained by the spatial extent that they can cover while recording neural activity. Neuroimaging techniques can thus prove valuable to probe the many areas involved in stereopsis simultaneously. However, such techniques typically provide low resolution signals that are far from representing local neural activity. As I mentioned in Chapter 4, advances in ultra-high field magnetic resonance imaging may help in overcoming this limitation to a certain extent. In Chapter 5, I demonstrated that it is possible to extract stereoscopic information from BOLD signals recorded at submillimeter resolution, suggesting that more comprehensive experiments will become possible as data collection and analysis tools for ultra-high field imaging keep improving \cite{Huber:2015ao,Kok:2016fk}. Whole-brain imaging at submillimeter resolution would provide us with the most comprehensive view of the stereoscopic system to date, potentially detailing a blueprint of layer-to-layer connectivity across the multiple visual areas involved in stereopsis. Such exploratory approach could then be used to guide targeted and powerful experiments using invasive techniques.




%%% ----------------------------------------------------------------------

% ------------------------------------------------------------------------

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
