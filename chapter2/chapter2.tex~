\chapter{Layer-dependent Activity in V1 during Stereopsis}
\ifpdf
    \graphicspath{{chapter3/chapter3-figs/PNG/}{chapter3/chapter3-figs/PDF/}{chapter3/chapter3-figs/}}
\else
    \graphicspath{{chapter3/chapter3-figs/EPS/}{chapter3/chapter3-figs/}}
\fi

\renewcommand{\runningTitle}{Layer-dependent fMRI and stereopsis}
\markboth{\MakeUppercase{\thechapter. \runningTitle }}{\thechapter. \runningTitle}

\section{Introduction}

The positional difference between the images captured by the left and right eyes, known as binocular disparity, is a highly informative cue to depth perception (Howard and Rodgers, 2002). The process of estimating depth from binocular disparity (i.e. stereopsis) is a complex process and requires multiple computational steps (Marr and Poggio, 1976). To date, the neural mechanisms that solve this problem remain unknown. Current models provide excellent mechanistic understanding of the first stages of binocular processing in primary visual cortex (Ozhawa et al., 1990). However, a multitude of other areas are thought to be important for binocular disparity (Orban et al., 2006; Parker, 2007), and their exact roles in supporting stereopsis remain unknown.
Disparity processing is thought to begin in primary visual cortex, where many disparity selective neurons exist (Barlow et al., 1967). We currently possess models that describe how disparity selectivity neurons arise in V1, and account for many of their response properties (Ohzawa et al., 1990; Samonds et al., 2013). However, the responses of these neurons are poorly related to stereoscopic perception (Cumming and Parker, 1997; Cumming and Parker, 1999). Instead, perceptually related signals can be found in many extrastriate areas such as V2 (Nienborg et al., 2007), V4 (Shiozaki et al., 2012), MT (Krug et al., 2011) and dorsomedial visual cortex (Backus et al., 2001; Tsao et al., 2003; Preston et al., 2008), although their contribution to disparity processing is not well understood. In any case, evidence suggests that disparity selective neurons in primary visual cortex, alone, can not support our stereoscopic vision.
However, primary visual cortex is not only involved in the analysis of low-level visual features (e.g. orientation, disparity), but also in determining how the activity in higher visual areas influences perception. For instance, V1 gates the perception of moving phosphenes after magnetic stimulation applied to V5 (Silvanto et al, 2005). V1 has also been associated with image segmentation based on different visual cues (Lamme et al., 1993; Zipser et al., 1996). Feedback mechanisms are thought to mediate these processes (Hupé et al., 1998), mainly via excitatory connections from extrastriate areas to deep layers of V1 (Self et al., 2013). 
Feedback mechanisms have also been proposed to carry information concerning the three-dimensional surfaces defined by binocular disparity (Zipser et al., 1996; Sugita, 1999). However, the laminar circuits involved in these processes remain unknown. Here, we used ultra-high field imaging to study laminar profiles of activity in response to correlated random dot stereograms, which elicit perception of a surface in depth, and contrast this against responses to anti-correlated random dot stereograms, for which a surface in depth cannot be perceived. We found that coherent surfaces in depth elicited stronger responses in deep layers of primary visual cortex in humans, which are the main recipient of extrastriate feedback connections. Our results indicate that higher order visual areas send feedback signals to V1 that may help in perceptual integration of local disparity elements into continuous three-dimensional surfaces.


\section{Materials and Methods}

\subsection{Participants}
Eight subjects aged between 25 – 40 years (five male, including authors N.G., A.E.W.) participated in the study. Participants provided informed consent and procedures were approved by the Ethics Committee of the Faculty of Psychology and Neuroscience at Maastricht University. All participants had normal or corrected-to-normal vision and did not present stereo deficits.

\subsection{Stimuli and design}
Stimuli were presented using a fiber optics goggle system (Silent Vision SV-7021, Avotec, Inc., Stuart, FL). The resulting visual field was approximately 30° horizontally by 23° vertically, and the viewing distance was approximately 6 cm. Stimuli consisted of random dot stereograms (12 x 12°, 34 dots/deg2) with a mid-gray background. To promote stable vergence, the stimuli were surrounded by a static grid of squares. Dots in the stereogram followed a black or white Gaussian luminance profile, subtending 0.07° at half maximum. In the center of the stereogram, four wedges were equally distributed around a circular aperture (1.2°), each subtending 10 degrees in the radial direction and 70 degrees in polar angle, with a 20 degrees gap between wedges (Fig. 1a). The wedges were presented in correlated or anti-correlated forms and had crossed or uncrossed disparity (10 arcmin, ± 0.5 arcmin jitter). The surrounding was always presented in correlated form at zero disparity. At a given time point, all wedges presented the same disparity and stereo correspondence level. To reduce adaptation, we applied a random polar rotation to the set of wedges such that the disparity edges of the stimuli were in different locations for each stimulus presentation. In the center of the wedge field, we presented a fixation square (side length = 1°) paired with horizontal and vertical nonius lines.
Stereo correspondence and disparity sign were held constant during 12 second blocks, during which we presented 10 stimuli (900 ms on, ISI 300 ms). During each acquisition run, we presented each combination of correspondence and disparity sign 10 times, resulting in 40 blocks. In addition, there was a fixation block at the start and the end of each run. Each run lasted 504 seconds (42 blocks x 12 s), and we collected six to seven runs in each imaging session. On each run, we asked participants to fixate in the central fixation square while performing a Vernier detection task (Preston et al, 2008).
For localizing activity to stimulus delivery and for quality control purposes, participants undertook one experimental run during which we presented radial checkerboard flickering at 8 Hz. The checkerboard was positioned in the center of the screen and subtended 12 degrees in eccentricity. Participants were instructed to fixate in the center of the screen passively while viewing the stimuli. The checkerboard was presented during 2 seconds, and was followed by a blank period of 14 seconds. A 16 second blank period was included at the beginning and at the end of the run.
As an additional control run, participants viewed similar checkerboards that were in turn presented monocularly. The same checkerboard flickered at 8 Hz and was presented either to the left or to the right eye during blocks of 20 seconds. The run consisted of 24 randomized blocks of stimulation to the left or right eyes, intercalated with five equally spaced periods of rest, each one with the duration of 20 seconds.

\subsection{Imaging}
Imaging sessions were performed at the Maastricht Brain Imaging Center (Maastricht, The Netherlands). We used a 7 Tesla Siemens scanner with a 16-channel surface coil system. Motion was restricted by the use of foam padding. Anatomical volumes were acquired in the beginning of each session (3D-MPRAGE, 256 slices, FOV = 230x230 mm2, matrix size = 384x384, 0.6 mm isotropic resolution), followed by a proton-density weighted volume with the same resolution and matrix size, which we used for inhomogeneity correction. We then acquired blood oxygen level-dependent (BOLD) signals during stimuli delivery. For the localizer experiment, we used two dimensional echo-planar imaging (gradient-echo; TE/TR = 24/2000 ms; flip angle = 70º; FOV = 150x150 mm2, matrix size = 136x136; 28 slices; 1.1 mm3 isotropic resolution). For the main experiment, we acquired BOLD signals using three-dimensional gradient recalled spin-echo imaging with inner volume selection (3D GRASE; TE/TR = 38/2000 ms; FOV = 24x128x9.6 mm3, matrix size = 30x160x12, APxRLxFH; 0.8 mm3 isotropic resolution). Slice positioning was guided by visual identification of the calcarine sulcus. The acquisition volume was placed along the calcarine sulcus, and efforts were made to cover both banks of the sulcus in both hemispheres, when possible. 
Imaging data were analyzed using BrainVoyager QX 2.8.2 (Brain Innovation, Maastricht, The Netherlands) and custom Matlab code (The Mathworks Inc, Natick, MA). Field inhomogeneity in anatomical scans was corrected by dividing the structural volume by the respective proton-density weighted volume. When low frequency variations remained, an additional automatic inhomogeneity correction step was performed. Anatomical volumes were then manually segmented to ensure high-quality cortical representations. The resulting segmented volume was used to compute estimates of cortical thickness following the Laplace method (Jones et al., 2000), from which we could later derive streamlines at different cortical depths for laminar analysis. Details on this procedure are described elsewhere (Zimmermann et al., 2011). Functional data were preprocessed in the functional native space. Head motion was estimated using trilinear interpolation and subsequently corrected using sinc interpolation. Low-frequency fluctuations were removed using a GLM with Fourier basis set at 2 cycles per run. Preprocessed data were then coregistered to the anatomical space and resampled using trilinear interpolation. 
We started our analysis by identifying regions of interest that covered activated areas in the calcarine sulcus. To do so, we fit a general linear model to the data, and look for positive differences between BOLD signals during stimulus delivery and rest periods. For further univariate analysis (i.e. using a general linear model), we defined regions of interest in a conservative way. In particular, we ensured that the region of interest covered areas that were well modeled during the main experiment (F-contrast, stimulus versus blank, p<.005, FDR-corrected). For multivariate analysis, we defined broader regions of interest based on the checkerboard localizer (F-contrast, stimulus versus blank, p<0.001, FDR-corrected), so as to obtain a reasonable pattern size for classification.
Using the cortical thickness measurements in these selected regions, we then computed nine equally spaced grids along the cortical sheet (0.1 to 0.9 in relative depth, with 0.1 increments; for details see Zimmermann et al., 2011). Each grid intersects the cortical sheet at a different depth, and therefore runs approximately along the cortical layers. Next, a cortical depth label was assigned to each voxel according to the nearest located cortical grid. This way, voxels that are assigned to different neighboring layers will not be duplicated. Additionally, neighboring layers will not necessarily contain neighboring voxels. The cortical depth label assigned to each voxel was then used to index functional data at different cortical depths.

\subsection{ General Linear Modeling}
For the stereo correspondence experiment, we modeled the BOLD signal using four conditions of interest (correlated, negative disparity; correlated, positive disparity; anti-correlated, negative disparity; anti-correlated, positive disparity). Advantage for stereo correlated stimuli was then tested by contrasting activity elicited by correlated versus anti-correlated blocks. For the control experiment, during which a flickering checkerboard was presented either to the left or to the right eyes, we contrasted activity during periods of left versus right eye stimulation. These univariate procedures yield a statistic for each voxel, which we can then index by the corresponding cortical depth label assigned above.

\subsection{ Multivoxel pattern analysis}
For each region-of-interest, we converted voxel time series to z-scores, and shifted the respective time course by two volumes (equivalent to four seconds) to account for the hemodynamic delay. Then, the median value across data-points within each condition block was taken, resulting in 40 activity patterns per run. We then trained a support vector machine classifier (Chang and Lin, 2011) with recursive feature elimination leaving one run out for cross-validation. These resulted in 240 patterns for training and 40 patterns for testing the model (less 40 training patterns for participant ML, for which we acquired six runs of the main experiment). In each cross-validation fold, recursive feature elimination was performed without re-estimating the model at each elimination step. In particular, we started by ranking the features (voxels) according to the weights that result from model estimation using all the features in the training set. Then, we iteratively tested the model in the remaining run, decreasing the number of features included at each iteration by eliminating the five features with lowest weights. This produced a vector of classification accuracies for different feature set sizes. 
During the model estimation step, the learning algorithm attributes a weight to each feature (i.e. voxel). The absolute value of each weight can be interpreted as the contribution of individual voxels in discriminating between different classes. Thus, for each cross-validation, we stored the absolute weights assigned to each voxel, and examine their distribution at different cortical depths. First, to compensate for baseline differences in model weights across cross-validations, absolute weights were z-normalized. Then, we grouped voxels into three groups according to their relative distance from the white matter: deep layers (from 0.1 to 0.3); intermediate layers (relative depths from 0.4-0.6); and superficial layers (from 0.7-0.9). Finally, we bootstrapped the mean of the normalized weights in each group (10000 resamples). As a control analysis, we repeated the same procedure after randomly shuffling cortical depth labels (10000 permutations).

\section{Results}
We recorded blood oxygenation level-dependent signals from the calcarine sulcus while participants viewed the monocular and binocular stimuli (Fig. 1). During the main experiment, participants fixated on a central cross while viewing random dot stereograms. In the central region of the stereograms, four concentric wedges were defined in correlated or anti-correlated form (Fig. 1a). As a control experiment, we also acquired responses to monocular stimulation - alternate periods of either left-eye or right-eye stimulation (Fig. 1b). In order to localize responsive areas, participants undertook an additional experiment, during which a flickering checkerboard was presented to both eyes, intermitted with blank periods (Fig. 1c).
Slice positioning was guided by visual identification of the calcarine sulcus (Fig. 2a). The reduced coverage and high-resolution demand minimal levels of head motion during the experiments, which was well controlled by four participants. The remaining datasets were discarded during preprocessing due to excessive motion (>1 mm within session). We obtained strong responses to stimulus delivery, and activated areas were well confined to the gray matter, as illustrated in a representative subject (Fig. 2b).

\subsection{Laminar distribution of activity (GLM)}
We started by examining the BOLD signal at different cortical depths as modeled by a general linear model. We found that the mean response to correlated versus anti-correlated stimuli is higher in deep cortical layers (Fig. 3a), and this tendency is observed at the single subject level (Fig. 3b, subjects HL, ML and TE). For one subject, the mean t-score was not significantly different from zero at any cortical depth (Fig. 3b, subject VK). 
Can the biases we observed be explained by overall signal strength or contrast-to-noise ratio? To answer this question, we examined the distribution of statistical scores resulting from comparing stimulus delivery versus rest periods during the main experiment (i.e. the same data). We did not find a bias towards deep layers in this case - instead, we observed a fairly homogeneous distribution across different cortical depths (Fig. 3c), as suggested by previous investigations (De Martino et al., 2013). That was also the case when we compared responses to a flickering checkerboards presented monocularly (left versus right eye) (Fig. 3d). Finally, when we compared the laminar profile of activity during the localizer data, which was acquired using a gradient-echo sequence, we found a clear bias towards superficial layers, as previous studies reported (Koopmans et al., 2010; Polimeni et al., 2010; De Martino et al. 2013).

\subsection{Classifier weights at different cortical depths}

In our first approach we used a general linear model to estimate how time-courses of individual voxels explain expected BOLD responses. Doing so entails the definition of a hemodynamic response function, which we assume to be equal at different cortical depths. However, studies suggest that such assumption may not hold true (Tian et al., 2010; Goense et al., 2012). Therefore, a GLM may model data differently at given depths, which can introduce biases in statistical scores.
An alternative approach is the use of multivariate decoding techniques, which often assume little about the hemodynamic response. Multi-voxel pattern analyses were previously used to decode depth information in human primary visual cortex with modest, but reliable prediction accuracies (Preston et al., 2008). Here, we used support vector machines classifiers to discriminate between correlated and anti-correlated stimuli based on fMRI activity. Subsequently, we examined the distribution of discriminative voxels as a function of cortical depth. 
First, we examined whether perceptual stable depth perception could be decoded from signals in primary visual cortex at sub-millimeter resolution. To do so, we started by computing decoding accuracies using cross-validated recursive feature elimination. In particular, we trained the model using the full feature set size (i.e. all voxels in the region of interest, see Methods), and ranked voxels according to their absolute model weight. Then, we iteratively tested the model in the training set, eliminating the least important features at each iteration. We found that moderate-to-high prediction accuracies in two participants (HL and ML), with higher performance achieved at around 500 features (Fig 4a,b). For the remaining two participants, the prediction accuracy was not significantly different from chance, and therefore we did not proceed with the analysis of these data.
In our previous analysis, we confirmed that it is possible to discriminate between perceptually coherent and incoherent binocular stimuli based on activity in primary visual cortex. But how is this information represented across different cortical layers? 
To shed light on this question, we asked which cortical layers contain signals that contribute to this discrimination. Based on our knowledge of laminar organization, feedforward connections from subcortical areas are thought to mainly spread through intermediate and superficial layers of V1, and therefrom to extrastriate cortex. Contrarily, deep layers in V1 are the main recipients of feedback connections from extrastriate cortex (Felleman and Van Essen, 1991; Callaway, 1998). Therefore, the laminar distribution of classification weights may help in identifying the source of information necessary to discriminate between coherent and incoherent stereoscopic stimuli. 
We examined the distribution of classifier weights at different cortical depths. For each cross-validation fold, we started by normalizing the absolute weights (z-score) to remove differences in baseline. Then, we grouped voxels into three groups - deep, intermediate and superficial layers, according to their relative cortical depth. Next, we computed the mean of the normalized weights for each of these groups (bootstrapping, 10000 resamples). We found that deep layers presented higher model weights when compared to middle and superficial layers, and this was consistently observed across cross-validations folds (Fig. 5a,b). We repeated the same procedure after randomly shuffling the cortical depth labels (10000 permutations) and compared the resulting distribution with the observed data. We found that the weights observed in deep layers were significantly higher for both subjects (p<0.001). These results suggest that deep layers are more informative of the perceptual stability of binocular stimuli.
Our previous approach has the advantage of avoiding binning features before running multivariate classification, and therefore use the whole pattern information available in the region of interest. However, accuracies can be sometimes more easily interpreted. As a confirmatory analysis, we computed the classification accuracy after grouping voxels according to their relative cortical depth - deep (0.1-0.3), intermediate (0.4-0.6) and superficial (0.7-0.9) layers. We then performed classification analysis including all voxels in each group, and confirmed that higher average prediction accuracies were observed in superficial layers for both subjects.


\section{Discussion}

Here we have examined how human primary visual cortex responds in the presence and absence of stable three-dimensional perception. We manipulated perceptual relevance by using correlated and anti-correlated random dot stereograms. Correlated stereograms could be easily fused to perceive a three-dimensional surface, while anti-correlated stimuli could not, and therefore did not elicit stable three-dimensional perception. Using ultra-high field imaging with isotropic sub-millimeter resolution, we investigated BOLD responses to these stimuli at different cortical layers of primary visual cortex. We observed enhanced activity in deep layers during periods of stable three-dimensional perception, while no difference in activity was found in superficial layers. In addition, multivariate analysis shows that deep cortical layers were the most informative in determining the three-dimensional stability of visual input.

In this study, we acquired BOLD signals at sub-millimeter resolution to investigate responses of neural populations in different cortical layers. Although the BOLD signal appears to be more locally registered to neural activity than previously thought (Siero et al., 2014), it is reasonable to assume that biases in type and amount of vasculature across the cortical layers (Duvernoy, 1981) may influence results. Therefore, we incorporated several measures to avoid vascular biases from interfering with the results. In particular, by scanning at ultra-high field, we greatly reduce macrovascular contributions (Gati et al., 1997; Ogawa et al., 1998; Ugurbil et al., 2003). Additionally, we chose to use a spin-echo based sequence (3D GRASE; Feinberg et al. 2008) to provide increased spatial specificity - this sequence has an estimated point-spread function of approximately 0.5 mm (Gaussian FWHM) and presents increased immunity to macrovascular contributions (De Martino et al., 2013). Indeed, our control analyses confirm that macrovascular contributions were well minimized, as shown by the laminar profiles of activity during stimulus delivery (Fig. 3). Data acquired with 3D GRASE show no evident bias towards specific layers (Fig. 3d), while a clear bias towards superficial layers was observed for data collected with gradient-echo EPI (Fig. 3f). A comparison between activity during periods of monocular stimulation (left versus right eye) showed no bias for higher statistical scores in particular cortical depths (Fig. 3e). Therefore, the enhanced activity found in deep layers in response to correlated versus anti-correlated stereograms could not be explained by differences in signal- or contrast-to-noise ratio.

Our results suggest that perception of three-dimensional structure from binocular disparity involves neural populations in V1. How can this observation be interpreted in the light of the computational processes that are thought to support stereoscopic processing in the brain? Several studies suggest that the stereo correspondence problem, critical for perceiving depth from binocular disparity, is solved in higher visual areas along the cortical hierarchy (Cumming and Parker, 1997; Janssen et al., 2003; Preston et al., 2008). In this sense, it is unlikely that the activation we observed in V1 was driven by a bottom-up process. Conversely, it has been proposed that feedback mechanisms modulate activity in V1 based on information derived from higher-order areas (Silvanto et al., 2005; Ban et al., 2014). For instance, information about three-dimensional configurations defined by binocular disparity can modulate the responses of neurons in V1 (Zipser et al., 1996; Sugita et al., 1999). It is therefore plausible that the responses we observed in primary visual cortex derive from feedback modulations by higher visual areas, in particular those where the stereo correspondence ambiguity has been solved.

We found information on three-dimensional structure predominantly in deep layers of V1. Above, we argued that this information is most certainly derived from feedback contributions from higher visual areas. Because different cortical depths present a unique pattern of feedforward, horizontal and feedback connections, we can further assess whether our findings are supported by anatomical evidence. Indeed, deep layers are the main recipient of feedback connections originating from extrastriate areas, while feedforward connections from V1 to higher visual areas occur primarily in superficial layers (Felleman and Van Essen, 1991; Callaway, 1998). Therefore, these findings are in excellent agreement with the pattern of anatomical connections observed in V1.

Our findings indicate that information on the three-dimensional structure of a scene can modulate activity in deep layers of V1 via feedback mechanisms. It is interesting to speculate about the purpose of this information. Based on the characteristics of our stimuli and electrophysiological evidence, we argue that this information contributes to figure-ground segmentation. Recent physiology evidence suggests that this process relies in two main computational stages: feedforward and lateral connections in superficial layers of V1 are involved in detecting edges defined by discontinuities in low-level visual features (e.g. orientation), while filling-in processes are mediated by excitatory feedback connections from higher visual areas into deep layers in V1 (Self et al., 2013). In our random-dot stimuli, dots in the background region were always presented in correlated form - stereo correspondence was manipulated only within the wedge targets. Perceptually, this meant that observers could identify discontinuities in both classes of stimuli (Fig. 6, compare a and b). However, coherent integration (filling-in) of a surface in depth was not possible when targets were presented in anti-correlated form. Therefore, in contrasting the responses between these classes of stimuli, we mainly evaluate the process of surface integration. As mentioned above, this process is thought to be mediated by feedback connections from higher visual areas into deep layers of V1 (Self et al., 2013). Our findings entirely agree with this hypothesis.

This last point opens an interesting question: does the process of figure-ground segmentation of elements defined by different features (e.g. orientation and disparity) share common computational steps? Detailed investigations of figure-ground segmentation - such as those performed by Self and colleagues (2013) - using random dot stereograms may provide valuable evidence to answer this question. In particular, by manipulating the stereo correspondence of the stimuli, we may further dissociate the effects of boundary detection and region filling. For instance, consider a stereogram with zero disparity in the background and non-zero disparity in a given target region. If the background is presented in correlated form, discontinuities will be perceived independently of the stereo correspondence level in the target region. However, a coherent surface cannot be filled-in if the target is presented with anti-correlated disparity. Conversely, if the background and target are presented in anti-correlated form, no discontinuity can be perceived, even though the background and target regions effectively contain different feature levels (the background with zero disparity, and the target with non-zero disparity). Therefore, the use of stereograms may provide an additional degree of freedom in the manipulation of stimuli and therefore help in further dissociating the understanding the role of different cortical layers in the computational processes that underlie figure-ground segmentation.



% ------------------------------------------------------------------------

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
